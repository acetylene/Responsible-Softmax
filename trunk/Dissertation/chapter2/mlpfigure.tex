\begin{figure}[ht]
	\centering
	\begin{tikzpicture}[shorten >=1pt,->,draw=black!50, node distance=\layersep]
	\tikzstyle{every pin edge}=[<-,shorten <=1pt]
	\tikzstyle{neuron}=[circle,fill=black!25,minimum size=17pt,inner sep=0pt]
	\tikzstyle{input neuron}=[neuron, fill=green!20];
	\tikzstyle{output neuron}=[neuron, fill=red!20];
	\tikzstyle{hidden neuron}=[neuron, fill=blue!20];
	\tikzstyle{annot} = [text width=4em, text centered]
	
	% Draw the input layer nodes
	\foreach \name / \y in {1,...,5}
	% This is the same as writing \foreach \name / \y in {1/1,2/2,3/3,4/4}
	\node[input neuron] (I-\name) at (0,-\y) {\(x_\y\)};
	
	% Draw the hidden layer nodes
	\foreach \name / \y in {1,...,6}
	\path[yshift=0.5cm]
	node[hidden neuron] (H-\name) at (\layersep,-\y cm) {\(z_\y\)};
	
	% Draw the output layer nodes
	\foreach \name / \y in {1,...,3}
		\node[output neuron,pin={[pin edge={->}]right:\(\hat{y}_\y\)}] (O-\name) at (2*\layersep,-1 cm-\y cm) {\(y_\y\)};
	
	% Connect every node in the input layer with every node in the
	% hidden layer.
	\foreach \source in {1,...,5}
	\foreach \dest in {1,...,6}
	\path (I-\source) edge (H-\dest);
	
	% Connect every node in the hidden layer with the output layer
	\foreach \source in {1,...,6}
	\foreach \dest in {1,...,3}
	\path (H-\source) edge (O-\dest);
	
	% Annotate the layers
	\node[annot,above of=H-1, node distance=1cm] (hl) {Hidden layer};
	\node[annot,left of=hl] {Input layer};
	\node[annot,right of=hl] {Output layer};
		
	\end{tikzpicture}
		\caption[Network graph of a multilayer perceptron.]{A graph model of a single hidden layer MLP with 5 inputs, 3 output and 6 hidden layer nodes. The output of each layer is determined by composing a linear map with a nonlinear map. The general form of this nonlinear map is determined at the outset, though it may have trained parameters. The linear map is determined through a set of learned weights.}
	\label{fig:MLP}
\end{figure}