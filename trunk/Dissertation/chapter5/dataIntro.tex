\label{ch:experiments}
Having described the responsible softmax layer, this dissertation now focuses on performance of that layer comparison of this layer to standard techniques.  In doing so, the analysis rests on two aspects, running time and measures of correctness. For measures of correct classification, many methods rely on metrics such as precision and accuracy.  For multiclass problems, and for training with imbalanced data, such measures can be uninformative or deceptive in their approach.  This chapter discusses some of the more common approaches and uses a few of them to evaluate how the \RS layer affects classification.

In the area of running time, convergence of \DR to a stable point greatly affects any additional compute time. Lemma \ref{hess} and the discussion from chapter \ref{respLayer} about differentiation of the responsibility operator help immensely in understanding how the distance \(a_n := \norm{R(F,\bm\pi_n)-\bm\pi_n} \) changes as \( n\rightarrow\oo \).  The hessian of \( \ell(F,\bm\pi) \)  with respect to \( \bm p \) is closely related to the matrix \( F \). Thus iteration of \( R(F,\bm\pi) \) could reasonably converge like \( e^{-\gl} \), where \( \gl = \max \op{svd}(F) \) is the largest of singular values of \( F \).  Empirically this is the case, as discussed in section \ref{sect:expConvRate}.

When measuring correct classification, comparison of models to reasonable baselines provides intuition and discernment. Two base models for comparison to \RS are the standard softmax layer, and use of appropriate weights to match priors on training labels.  Using weights to match the  mixture proportions may be accomplished through several methods. In this dissertation, the model that will be used is a \RS layer with a fixed \( \bm\pi_0 \). This will be discussed further in section \ref{sect:commonLayerConfig}.

In training several different neural nets, numerous settings produce diverse effects on final performance. Initialization of weights and hyperparameter selection provide good changes to study such effects. This means running numerical experiments involving several mostly identical neural nets.  Since the \RS layer introduces a new hyperparameter \( C \), this means testing layers with different values of \( C \).  As will be seen in sections \ref{sect:expConvRate} and \ref{sect:GMMresults}, smaller values of \( C\) are generally better.

Classification performance of a given method also varies greatly among data sets.  Both synthetically produced and naturally gathered data sets accentuate different qualities of classification performance. Because the \RS layer is inspired by mixture modeling, training on generated Gaussian mixture model data is one natural choice for synthetic data. The MNIST data set was chosen as a familiar baseline for the behavior of an \RS layer. More detailed discussion of the choices that went into data set selection is in section \ref{sect:dataSelection}.

It is also the case that distinct evaluation metrics provide distinct insights to distinct classification methods. The fact that no model does well (or poorly) on all metrics necessitates application of several metrics to compare different models. A standard set of metrics used for classification are precision and accuracy. These have several drawbacks, especially in the multiclass setting, but they are still very informative. In the case such as testing with generated data, an idealized model is available so the performance of the neural nets can be compared to the idealized model. Discussions on metric selection are in section \ref{sect:eval}. Results of the experiments are covered in sections \ref{sect:GMMresults} and \ref{sect:MNISTresults}.

The final section of this chapter discusses The conclusions of the analyses and focuses on possible future studies.